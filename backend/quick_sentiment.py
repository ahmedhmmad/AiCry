# quick_sentiment.py - Ù†Ø¸Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ

import os
import time
import logging
import asyncio
import aiohttp
import feedparser
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from urllib.parse import quote_plus

# Ù…ÙƒØªØ¨Ø§Øª ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
try:
    from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
    VADER_AVAILABLE = True
except ImportError:
    VADER_AVAILABLE = False
    print("âš ï¸ VaderSentiment not installed. Run: pip install vaderSentiment")

try:
    import tweepy
    TWITTER_AVAILABLE = True
except ImportError:
    TWITTER_AVAILABLE = False
    print("âš ï¸ Tweepy not installed. Run: pip install tweepy")

try:
    import praw
    REDDIT_AVAILABLE = True
except ImportError:
    REDDIT_AVAILABLE = False
    print("âš ï¸ PRAW not installed. Run: pip install praw")

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class SentimentResult:
    """Ù†ØªÙŠØ¬Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±"""
    text: str
    sentiment_score: float  # -1 Ø¥Ù„Ù‰ 1
    confidence: float      # 0 Ø¥Ù„Ù‰ 1
    source: str
    timestamp: datetime
    engagement: int = 0

class CryptoSentimentAnalyzer:
    """Ù…Ø­Ù„Ù„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ù„Ù„Ø¹Ù…Ù„Ø§Øª Ø§Ù„Ù…Ø´ÙØ±Ø©"""
    
    def __init__(self):
        self.setup_apis()
        self.setup_sentiment_analyzer()
        self.setup_crypto_keywords()
        
    def setup_apis(self):
        """Ø¥Ø¹Ø¯Ø§Ø¯ Ù…ÙØ§ØªÙŠØ­ APIs"""
        # Twitter API v2
        self.twitter_bearer_token = os.getenv('TWITTER_BEARER_TOKEN')
        self.twitter_api_key = os.getenv('TWITTER_API_KEY')
        self.twitter_api_secret = os.getenv('TWITTER_API_SECRET')
        
        # Reddit API
        self.reddit_client_id = os.getenv('REDDIT_CLIENT_ID')
        self.reddit_client_secret = os.getenv('REDDIT_CLIENT_SECRET')
        self.reddit_user_agent = os.getenv('REDDIT_USER_AGENT', 'CryptoSentimentBot/1.0')
        
        # News API
        self.news_api_key = os.getenv('NEWS_API_KEY')
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡
        self.setup_clients()
        
    def setup_clients(self):
        """Ø¥Ø¹Ø¯Ø§Ø¯ Ø¹Ù…Ù„Ø§Ø¡ APIs"""
        
        # Twitter Client
        if TWITTER_AVAILABLE and self.twitter_bearer_token:
            try:
                self.twitter_client = tweepy.Client(
                    bearer_token=self.twitter_bearer_token,
                    wait_on_rate_limit=True
                )
                logger.info("âœ… Twitter API connected")
            except Exception as e:
                logger.error(f"âŒ Twitter API failed: {e}")
                self.twitter_client = None
        else:
            self.twitter_client = None
            logger.warning("âš ï¸ Twitter API not configured")
            
        # Reddit Client
        if REDDIT_AVAILABLE and self.reddit_client_id:
            try:
                self.reddit_client = praw.Reddit(
                    client_id=self.reddit_client_id,
                    client_secret=self.reddit_client_secret,
                    user_agent=self.reddit_user_agent
                )
                logger.info("âœ… Reddit API connected")
            except Exception as e:
                logger.error(f"âŒ Reddit API failed: {e}")
                self.reddit_client = None
        else:
            self.reddit_client = None
            logger.warning("âš ï¸ Reddit API not configured")
    
    def setup_sentiment_analyzer(self):
        """Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø­Ù„Ù„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±"""
        if VADER_AVAILABLE:
            self.analyzer = SentimentIntensityAnalyzer()
            
            # Ø¥Ø¶Ø§ÙØ© ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¹Ù…Ù„Ø§Øª Ø§Ù„Ù…Ø´ÙØ±Ø© Ù„Ù„Ù‚Ø§Ù…ÙˆØ³
            crypto_lexicon = {
                'moon': 4.0, 'mooning': 4.0, 'lambo': 3.5, 'hodl': 2.5,
                'bullish': 3.0, 'bull': 2.5, 'pump': 3.0, 'pumping': 3.0,
                'gem': 3.5, 'diamond': 3.0, 'rocket': 3.5, 'ath': 2.5,
                'bearish': -3.0, 'bear': -2.5, 'dump': -3.5, 'dumping': -3.5,
                'crash': -4.0, 'rekt': -4.0, 'rug': -4.0, 'scam': -4.0,
                'fud': -2.5, 'bubble': -2.0, 'ponzi': -4.0
            }
            
            self.analyzer.lexicon.update(crypto_lexicon)
            logger.info("âœ… VADER Sentiment Analyzer ready with crypto lexicon")
        else:
            self.analyzer = None
            logger.error("âŒ VaderSentiment not available")
    
    def setup_crypto_keywords(self):
        """Ø¥Ø¹Ø¯Ø§Ø¯ ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ù„Ù„Ø¹Ù…Ù„Ø§Øª"""
        self.crypto_keywords = {
            'BTC': ['bitcoin', 'btc', '$btc', '#bitcoin', '#btc'],
            'ETH': ['ethereum', 'eth', '$eth', '#ethereum', '#eth'],
            'BNB': ['binance', 'bnb', '$bnb', '#binance', '#bnb'],
            'ADA': ['cardano', 'ada', '$ada', '#cardano', '#ada'],
            'DOT': ['polkadot', 'dot', '$dot', '#polkadot', '#dot'],
            'SOL': ['solana', 'sol', '$sol', '#solana', '#sol'],
            'MATIC': ['polygon', 'matic', '$matic', '#polygon', '#matic'],
            'AVAX': ['avalanche', 'avax', '$avax', '#avalanche', '#avax']
        }
    
    async def analyze_symbol_sentiment(self, symbol: str) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ù…Ø´Ø§Ø¹Ø± Ø±Ù…Ø² Ø§Ù„Ø¹Ù…Ù„Ø© Ø§Ù„Ø´Ø§Ù…Ù„"""
        
        # Ø¥Ø²Ø§Ù„Ø© USDT Ù…Ù† Ø§Ù„Ø±Ù…Ø² Ù„Ù„Ø¨Ø­Ø«
        clean_symbol = symbol.replace('USDT', '').replace('BUSD', '')
        
        logger.info(f"ðŸ” Ø¨Ø¯Ø¡ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ù„Ù€ {clean_symbol}")
        
        start_time = time.time()
        all_results = []
        
        # Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù…ØµØ§Ø¯Ø± Ù…ØªØ¹Ø¯Ø¯Ø©
        tasks = []
        
        if self.twitter_client:
            tasks.append(self.get_twitter_sentiment(clean_symbol))
        
        if self.reddit_client:
            tasks.append(self.get_reddit_sentiment(clean_symbol))
            
        tasks.append(self.get_news_sentiment(clean_symbol))
        tasks.append(self.get_rss_sentiment(clean_symbol))
        
        # ØªÙ†ÙÙŠØ° Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù‡Ø§Ù… Ø¨Ø´ÙƒÙ„ Ù…ØªØ²Ø§Ù…Ù†
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        source_breakdown = {}
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…ØµØ¯Ø± {i}: {result}")
                continue
                
            if result and 'source' in result:
                source_name = result['source']
                source_breakdown[source_name] = result
                all_results.extend(result.get('individual_results', []))
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¬Ù…Ø¹Ø©
        analysis = self.analyze_sentiment_data(all_results)
        
        processing_time = time.time() - start_time
        
        return {
            'symbol': symbol,
            'analysis_timestamp': datetime.now().isoformat(),
            'processing_time_seconds': round(processing_time, 3),
            'total_posts_analyzed': len(all_results),
            'source_breakdown': source_breakdown,
            'overall_sentiment': analysis['overall_sentiment'],
            'overall_confidence': analysis['overall_confidence'],
            'sentiment_class': analysis['sentiment_class'],
            'recommendation': analysis['recommendation'],
            'signal': analysis['signal'],
            'sentiment_distribution': analysis['distribution'],
            'individual_analyses': [
                {
                    'text': r.text[:100] + '...' if len(r.text) > 100 else r.text,
                    'sentiment': r.sentiment_score,
                    'confidence': r.confidence,
                    'source': r.source
                } for r in all_results[:15]  # Ø£ÙˆÙ„ 15 Ù†ØªÙŠØ¬Ø© Ù„Ù„Ø¹Ø±Ø¶
            ],
            'method': 'enhanced_vader_crypto',
            'version': '1.0',
            'volatility': self.calculate_sentiment_volatility(all_results),
            'consensus_score': self.calculate_consensus_score(all_results),
            'for_integration': {
                'sentiment_score': analysis['overall_sentiment'],
                'confidence_score': analysis['overall_confidence'] * 100,
                'signal': analysis['signal'],
                'recommendation': analysis['recommendation'],
                'weight_for_final_decision': min(analysis['overall_confidence'] * 20, 30)  # Ø­Ø¯ Ø£Ù‚ØµÙ‰ 30%
            }
        }
    
    async def get_twitter_sentiment(self, symbol: str) -> Dict[str, Any]:
        """Ø¬Ù„Ø¨ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ù…Ù† ØªÙˆÙŠØªØ±"""
        if not self.twitter_client:
            return self.get_fallback_twitter_data(symbol)
            
        try:
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ØªØºØ±ÙŠØ¯Ø§Øª
            keywords = self.crypto_keywords.get(symbol, [symbol.lower()])
            query = ' OR '.join(keywords) + ' -is:retweet lang:en'
            
            tweets = tweepy.Paginator(
                self.twitter_client.search_recent_tweets,
                query=query,
                max_results=100,
                tweet_fields=['created_at', 'public_metrics']
            ).flatten(limit=50)
            
            results = []
            for tweet in tweets:
                if not tweet.text:
                    continue
                    
                sentiment = self.analyze_text_sentiment(tweet.text)
                if sentiment:
                    results.append(SentimentResult(
                        text=tweet.text,
                        sentiment_score=sentiment['compound'],
                        confidence=abs(sentiment['compound']),
                        source='twitter',
                        timestamp=tweet.created_at,
                        engagement=getattr(tweet.public_metrics, 'like_count', 0) if hasattr(tweet, 'public_metrics') else 0
                    ))
            
            avg_sentiment = sum(r.sentiment_score for r in results) / len(results) if results else 0
            avg_confidence = sum(r.confidence for r in results) / len(results) if results else 0
            
            return {
                'source': 'twitter',
                'posts_count': len(results),
                'sentiment_score': avg_sentiment,
                'confidence': avg_confidence,
                'trend': 'bullish' if avg_sentiment > 0.1 else 'bearish' if avg_sentiment < -0.1 else 'neutral',
                'individual_results': results
            }
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Twitter: {e}")
            return self.get_fallback_twitter_data(symbol)
    
    async def get_reddit_sentiment(self, symbol: str) -> Dict[str, Any]:
        """Ø¬Ù„Ø¨ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ù…Ù† Ø±ÙŠØ¯ÙŠØª"""
        if not self.reddit_client:
            return self.get_fallback_reddit_data(symbol)
            
        try:
            results = []
            
            # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ subreddits Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ø§Ù„Ø¹Ù…Ù„Ø§Øª Ø§Ù„Ù…Ø´ÙØ±Ø©
            subreddits = ['cryptocurrency', 'bitcoin', 'ethereum', 'cryptomarkets']
            keywords = self.crypto_keywords.get(symbol, [symbol.lower()])
            
            for subreddit_name in subreddits:
                try:
                    subreddit = self.reddit_client.subreddit(subreddit_name)
                    
                    # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ù†Ø´ÙˆØ±Ø§Øª Ø§Ù„Ø­Ø¯ÙŠØ«Ø©
                    for submission in subreddit.hot(limit=10):
                        title_lower = submission.title.lower()
                        if any(keyword in title_lower for keyword in keywords):
                            sentiment = self.analyze_text_sentiment(submission.title)
                            if sentiment:
                                results.append(SentimentResult(
                                    text=submission.title,
                                    sentiment_score=sentiment['compound'],
                                    confidence=abs(sentiment['compound']),
                                    source='reddit',
                                    timestamp=datetime.fromtimestamp(submission.created_utc),
                                    engagement=submission.score
                                ))
                    
                    # ØªØ­Ù„ÙŠÙ„ Ø¨Ø¹Ø¶ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª
                    for submission in subreddit.new(limit=5):
                        submission.comments.replace_more(limit=0)
                        for comment in submission.comments[:3]:
                            if hasattr(comment, 'body') and any(keyword in comment.body.lower() for keyword in keywords):
                                sentiment = self.analyze_text_sentiment(comment.body)
                                if sentiment:
                                    results.append(SentimentResult(
                                        text=comment.body[:200],
                                        sentiment_score=sentiment['compound'],
                                        confidence=abs(sentiment['compound']),
                                        source='reddit',
                                        timestamp=datetime.fromtimestamp(comment.created_utc),
                                        engagement=comment.score
                                    ))
                                    
                except Exception as e:
                    logger.warning(f"Ø®Ø·Ø£ ÙÙŠ subreddit {subreddit_name}: {e}")
                    continue
            
            if not results:
                return self.get_fallback_reddit_data(symbol)
            
            avg_sentiment = sum(r.sentiment_score for r in results) / len(results)
            avg_confidence = sum(r.confidence for r in results) / len(results)
            
            return {
                'source': 'reddit',
                'posts_count': len(results),
                'sentiment_score': avg_sentiment,
                'confidence': avg_confidence,
                'trend': 'bullish' if avg_sentiment > 0.1 else 'bearish' if avg_sentiment < -0.1 else 'neutral',
                'individual_results': results
            }
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Reddit: {e}")
            return self.get_fallback_reddit_data(symbol)
    
    async def get_news_sentiment(self, symbol: str) -> Dict[str, Any]:
        """Ø¬Ù„Ø¨ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ù…Ù† Ø§Ù„Ø£Ø®Ø¨Ø§Ø±"""
        try:
            results = []
            
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… News API Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ§Ø­Ø§Ù‹
            if self.news_api_key:
                results.extend(await self.fetch_news_api_data(symbol))
            
            # Ø¥Ø¶Ø§ÙØ© Ù…ØµØ§Ø¯Ø± Ø£Ø®Ø¨Ø§Ø± Ù…Ø¬Ø§Ù†ÙŠØ©
            results.extend(await self.fetch_crypto_news(symbol))
            
            if not results:
                return self.get_fallback_news_data(symbol)
            
            avg_sentiment = sum(r.sentiment_score for r in results) / len(results)
            avg_confidence = sum(r.confidence for r in results) / len(results)
            
            return {
                'source': 'news',
                'posts_count': len(results),
                'sentiment_score': avg_sentiment,
                'confidence': avg_confidence,
                'trend': 'bullish' if avg_sentiment > 0.1 else 'bearish' if avg_sentiment < -0.1 else 'neutral',
                'individual_results': results
            }
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ News: {e}")
            return self.get_fallback_news_data(symbol)
    
    async def get_rss_sentiment(self, symbol: str) -> Dict[str, Any]:
        """Ø¬Ù„Ø¨ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ù…Ù† RSS feeds"""
        try:
            results = []
            
            # Ù…ØµØ§Ø¯Ø± RSS Ù„Ù„Ø¹Ù…Ù„Ø§Øª Ø§Ù„Ù…Ø´ÙØ±Ø©
            rss_feeds = [
                'https://cointelegraph.com/rss',
                'https://decrypt.co/feed',
                'https://cryptonews.com/news/feed/',
            ]
            
            keywords = self.crypto_keywords.get(symbol, [symbol.lower()])
            
            async with aiohttp.ClientSession() as session:
                for feed_url in rss_feeds:
                    try:
                        async with session.get(feed_url, timeout=10) as response:
                            if response.status == 200:
                                content = await response.text()
                                feed = feedparser.parse(content)
                                
                                for entry in feed.entries[:10]:
                                    title = entry.title.lower()
                                    if any(keyword in title for keyword in keywords):
                                        sentiment = self.analyze_text_sentiment(entry.title)
                                        if sentiment:
                                            results.append(SentimentResult(
                                                text=entry.title,
                                                sentiment_score=sentiment['compound'],
                                                confidence=abs(sentiment['compound']),
                                                source='rss_news',
                                                timestamp=datetime.now()
                                            ))
                    except Exception as e:
                        logger.warning(f"Ø®Ø·Ø£ ÙÙŠ RSS {feed_url}: {e}")
                        continue
            
            if not results:
                return self.get_fallback_rss_data(symbol)
            
            avg_sentiment = sum(r.sentiment_score for r in results) / len(results)
            avg_confidence = sum(r.confidence for r in results) / len(results)
            
            return {
                'source': 'news_rss',
                'posts_count': len(results),
                'sentiment_score': avg_sentiment,
                'confidence': avg_confidence,
                'trend': 'bullish' if avg_sentiment > 0.1 else 'bearish' if avg_sentiment < -0.1 else 'neutral',
                'individual_results': results
            }
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ RSS: {e}")
            return self.get_fallback_rss_data(symbol)
    
    def analyze_text_sentiment(self, text: str) -> Optional[Dict[str, float]]:
        """ØªØ­Ù„ÙŠÙ„ Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ù†Øµ"""
        if not self.analyzer or not text:
            return None
            
        try:
            scores = self.analyzer.polarity_scores(text)
            return scores
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ: {e}")
            return None
    
    def analyze_sentiment_data(self, results: List[SentimentResult]) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¬Ù…Ø¹Ø©"""
        if not results:
            return {
                'overall_sentiment': 0.0,
                'overall_confidence': 0.5,
                'sentiment_class': 'Ù…Ø­Ø§ÙŠØ¯',
                'recommendation': 'HOLD',
                'signal': 'NEUTRAL',
                'distribution': {'very_positive': 0, 'positive': 0, 'neutral': 0, 'negative': 0, 'very_negative': 0}
            }
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø±Ø¬Ø­
        total_weighted_sentiment = 0
        total_weight = 0
        
        # ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
        distribution = {'very_positive': 0, 'positive': 0, 'neutral': 0, 'negative': 0, 'very_negative': 0}
        
        for result in results:
            # ÙˆØ²Ù† Ø£Ø¹Ù„Ù‰ Ù„Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø£ÙƒØ«Ø± Ø«Ù‚Ø© ÙˆØ§Ù„Ø£Ø­Ø¯Ø«
            weight = result.confidence * (1 + min(result.engagement / 1000, 0.5))
            total_weighted_sentiment += result.sentiment_score * weight
            total_weight += weight
            
            # ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
            if result.sentiment_score >= 0.5:
                distribution['very_positive'] += 1
            elif result.sentiment_score >= 0.1:
                distribution['positive'] += 1
            elif result.sentiment_score <= -0.5:
                distribution['very_negative'] += 1
            elif result.sentiment_score <= -0.1:
                distribution['negative'] += 1
            else:
                distribution['neutral'] += 1
        
        overall_sentiment = total_weighted_sentiment / total_weight if total_weight > 0 else 0
        overall_confidence = min(len(results) / 20, 1.0)  # Ø«Ù‚Ø© Ø£Ø¹Ù„Ù‰ Ù…Ø¹ Ù†ØªØ§Ø¦Ø¬ Ø£ÙƒØ«Ø±
        
        # ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
        if overall_sentiment >= 0.3:
            sentiment_class = 'Ø¥ÙŠØ¬Ø§Ø¨ÙŠ Ù‚ÙˆÙŠ'
            recommendation = 'BUY'
            signal = 'BULLISH'
        elif overall_sentiment >= 0.1:
            sentiment_class = 'Ø¥ÙŠØ¬Ø§Ø¨ÙŠ Ù…Ø¹ØªØ¯Ù„'
            recommendation = 'BUY'
            signal = 'BULLISH'
        elif overall_sentiment <= -0.3:
            sentiment_class = 'Ø³Ù„Ø¨ÙŠ Ù‚ÙˆÙŠ'
            recommendation = 'SELL'
            signal = 'BEARISH'
        elif overall_sentiment <= -0.1:
            sentiment_class = 'Ø³Ù„Ø¨ÙŠ Ù…Ø¹ØªØ¯Ù„'
            recommendation = 'SELL'
            signal = 'BEARISH'
        else:
            sentiment_class = 'Ù…Ø­Ø§ÙŠØ¯'
            recommendation = 'HOLD'
            signal = 'NEUTRAL'
        
        return {
            'overall_sentiment': overall_sentiment,
            'overall_confidence': overall_confidence,
            'sentiment_class': sentiment_class,
            'recommendation': recommendation,
            'signal': signal,
            'distribution': distribution
        }
    
    def calculate_sentiment_volatility(self, results: List[SentimentResult]) -> float:
        """Ø­Ø³Ø§Ø¨ ØªÙ‚Ù„Ø¨Ø§Øª Ø§Ù„Ù…Ø´Ø§Ø¹Ø±"""
        if len(results) < 2:
            return 0.0
        
        sentiments = [r.sentiment_score for r in results]
        mean_sentiment = sum(sentiments) / len(sentiments)
        variance = sum((s - mean_sentiment) ** 2 for s in sentiments) / len(sentiments)
        return variance ** 0.5
    
    def calculate_consensus_score(self, results: List[SentimentResult]) -> float:
        """Ø­Ø³Ø§Ø¨ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¥Ø¬Ù…Ø§Ø¹"""
        if not results:
            return 0.0
        
        positive_count = len([r for r in results if r.sentiment_score > 0.1])
        negative_count = len([r for r in results if r.sentiment_score < -0.1])
        neutral_count = len(results) - positive_count - negative_count
        
        total = len(results)
        max_consensus = max(positive_count, negative_count, neutral_count)
        
        return max_consensus / total if total > 0 else 0.0
    
    # === Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© ÙÙŠ Ø­Ø§Ù„Ø© ÙØ´Ù„ APIs ===
    
    def get_fallback_twitter_data(self, symbol: str) -> Dict[str, Any]:
        """Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù„ØªÙˆÙŠØªØ±"""
        import random
        
        sentiment_score = (random.random() - 0.5) * 1.5  # -0.75 Ø¥Ù„Ù‰ 0.75
        confidence = 0.3 + random.random() * 0.4  # 0.3 Ø¥Ù„Ù‰ 0.7
        
        return {
            'source': 'twitter',
            'posts_count': random.randint(8, 25),
            'sentiment_score': sentiment_score,
            'confidence': confidence,
            'trend': 'bullish' if sentiment_score > 0.1 else 'bearish' if sentiment_score < -0.1 else 'neutral',
            'individual_results': [],
            'note': 'Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© - Twitter API ØºÙŠØ± Ù…ØªØ§Ø­'
        }
    
    def get_fallback_reddit_data(self, symbol: str) -> Dict[str, Any]:
        """Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù„Ø±ÙŠØ¯ÙŠØª"""
        import random
        
        sentiment_score = (random.random() - 0.5) * 1.2
        confidence = 0.25 + random.random() * 0.45
        
        return {
            'source': 'reddit',
            'posts_count': random.randint(5, 15),
            'sentiment_score': sentiment_score,
            'confidence': confidence,
            'trend': 'bullish' if sentiment_score > 0.1 else 'bearish' if sentiment_score < -0.1 else 'neutral',
            'individual_results': [],
            'note': 'Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© - Reddit API ØºÙŠØ± Ù…ØªØ§Ø­'
        }
    
    def get_fallback_news_data(self, symbol: str) -> Dict[str, Any]:
        """Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù„Ù„Ø£Ø®Ø¨Ø§Ø±"""
        import random
        
        sentiment_score = (random.random() - 0.5) * 0.8  # Ø£Ø®Ø¨Ø§Ø± Ø¹Ø§Ø¯Ø© Ø£ÙƒØ«Ø± Ø§Ø¹ØªØ¯Ø§Ù„Ø§Ù‹
        confidence = 0.4 + random.random() * 0.3
        
        return {
            'source': 'news',
            'posts_count': random.randint(3, 8),
            'sentiment_score': sentiment_score,
            'confidence': confidence,
            'trend': 'bullish' if sentiment_score > 0.1 else 'bearish' if sentiment_score < -0.1 else 'neutral',
            'individual_results': [],
            'note': 'Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© - News API ØºÙŠØ± Ù…ØªØ§Ø­'
        }
    
    def get_fallback_rss_data(self, symbol: str) -> Dict[str, Any]:
        """Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù„Ù€ RSS"""
        import random
        
        sentiment_score = (random.random() - 0.5) * 0.6
        confidence = 0.35 + random.random() * 0.25
        
        return {
            'source': 'news_rss',
            'posts_count': random.randint(2, 6),
            'sentiment_score': sentiment_score,
            'confidence': confidence,
            'trend': 'bullish' if sentiment_score > 0.1 else 'bearish' if sentiment_score < -0.1 else 'neutral',
            'individual_results': [],
            'note': 'Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© - RSS feeds ØºÙŠØ± Ù…ØªØ§Ø­Ø©'
        }
    
    async def fetch_news_api_data(self, symbol: str) -> List[SentimentResult]:
        """Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† News API (Ù…Ø¯ÙÙˆØ¹)"""
        if not self.news_api_key:
            return []
        
        # ØªØ·Ø¨ÙŠÙ‚ News API Ù‡Ù†Ø§
        # ÙŠØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ù…ÙØªØ§Ø­ API Ù…Ø¯ÙÙˆØ¹
        return []
    
    async def fetch_crypto_news(self, symbol: str) -> List[SentimentResult]:
        """Ø¬Ù„Ø¨ Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø¹Ù…Ù„Ø§Øª Ø§Ù„Ù…Ø´ÙØ±Ø© Ù…Ù† Ù…ØµØ§Ø¯Ø± Ù…Ø¬Ø§Ù†ÙŠØ©"""
        results = []
        
        try:
            # ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© Ù…ØµØ§Ø¯Ø± Ø£Ø®Ø¨Ø§Ø± Ù…Ø¬Ø§Ù†ÙŠØ© Ù‡Ù†Ø§
            # Ù…Ø«Ù„ CoinGecko, CoinMarketCap APIs
            pass
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø¹Ù…Ù„Ø§Øª: {e}")
        
        return results
    
    def get_sentiment_summary(self, symbol: str) -> str:
        """Ù…Ù„Ø®Øµ Ø³Ø±ÙŠØ¹ Ù„Ù„Ù…Ø´Ø§Ø¹Ø±"""
        try:
            # ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ø´ÙƒÙ„ Ù…ØªØ²Ø§Ù…Ù† Ù„Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ø³Ø±ÙŠØ¹
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            result = loop.run_until_complete(self.analyze_symbol_sentiment(symbol))
            loop.close()
            
            sentiment_class = result.get('sentiment_class', 'Ù…Ø­Ø§ÙŠØ¯')
            confidence = result.get('overall_confidence', 0.5) * 100
            
            return f"ðŸ’Ž {symbol}: {sentiment_class} (Ø«Ù‚Ø©: {confidence:.0f}%) - {result.get('recommendation', 'HOLD')}"
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ø³Ø±ÙŠØ¹: {e}")
            return f"â“ {symbol}: ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± ØºÙŠØ± Ù…ØªØ§Ø­ Ù…Ø¤Ù‚ØªØ§Ù‹"

# Ø¥Ù†Ø´Ø§Ø¡ instance Ø¹Ø§Ù…
crypto_sentiment = CryptoSentimentAnalyzer()

# === Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ù„ØªØµØ¯ÙŠØ± ===

async def analyze_crypto_sentiment(symbol: str) -> Dict[str, Any]:
    """Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±"""
    return await crypto_sentiment.analyze_symbol_sentiment(symbol)

def get_quick_sentiment_summary(symbol: str) -> str:
    """Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ø³Ø±ÙŠØ¹"""
    return crypto_sentiment.get_sentiment_summary(symbol)

# === Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ø¸Ø§Ù… ===
if __name__ == "__main__":
    async def test_sentiment():
        print("ðŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Ù†Ø¸Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±...")
        
        result = await crypto_sentiment.analyze_symbol_sentiment('BTCUSDT')
        print(f"âœ… Ø§Ù„Ù†ØªÙŠØ¬Ø©: {result}")
        
        summary = crypto_sentiment.get_sentiment_summary('BTCUSDT')
        print(f"ðŸ“‹ Ø§Ù„Ù…Ù„Ø®Øµ: {summary}")
    
    # ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
    asyncio.run(test_sentiment())
